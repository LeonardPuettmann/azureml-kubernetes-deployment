{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import (\n",
    "    KubernetesOnlineEndpoint,\n",
    "    KubernetesOnlineDeployment,\n",
    "    Model, \n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ") \n",
    "from azure.ai.ml.entities._deployment.resource_requirements_settings import (\n",
    "    ResourceRequirementsSettings,\n",
    ")\n",
    "from azure.ai.ml.entities._deployment.container_resource_settings import (\n",
    "    ResourceSettings,\n",
    ")\n",
    "\n",
    "from constants import SUBSCRIPTION_ID, RESOURCE_GROUP, WORKSPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "# Check if given credential can get token successfully.\n",
    "credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential, SUBSCRIPTION_ID, RESOURCE_GROUP, WORKSPACE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "\n",
    "loacl_endpoint_name = \"loacl\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = KubernetesOnlineEndpoint(\n",
    "    name=loacl_endpoint_name, \n",
    "    description=\"this is a sample local endpoint\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docker in c:\\users\\leopu\\onedrive\\programming\\python\\azure\\sdk-v2\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\leopu\\onedrive\\programming\\python\\azure\\sdk-v2\\lib\\site-packages (from docker) (1.5.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\leopu\\onedrive\\programming\\python\\azure\\sdk-v2\\lib\\site-packages (from docker) (2.28.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\leopu\\onedrive\\programming\\python\\azure\\sdk-v2\\lib\\site-packages (from docker) (1.26.14)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\leopu\\onedrive\\programming\\python\\azure\\sdk-v2\\lib\\site-packages (from docker) (305)\n",
      "Requirement already satisfied: packaging>=14.0 in c:\\users\\leopu\\onedrive\\programming\\python\\azure\\sdk-v2\\lib\\site-packages (from docker) (23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leopu\\onedrive\\programming\\python\\azure\\sdk-v2\\lib\\site-packages (from requests>=2.26.0->docker) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leopu\\onedrive\\programming\\python\\azure\\sdk-v2\\lib\\site-packages (from requests>=2.26.0->docker) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leopu\\onedrive\\programming\\python\\azure\\sdk-v2\\lib\\site-packages (from requests>=2.26.0->docker) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "\n",
    "!{sys.executable} -m pip install docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating local endpoint (loacl04021040089783) Done (0m 0s)\n",
      "Field 'mirror_traffic': This is an experimental field, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': None, 'scoring_uri': None, 'openapi_uri': None, 'name': 'loacl04021040089783', 'description': 'this is a sample local endpoint', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': WindowsPath('C:/Users/leopu/.azureml/inferencing/loacl04021040089783'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001786FECD610>, 'auth_mode': 'key', 'location': None, 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(path=r\".\\model\\model\\sklearn_regression_model.pkl\")\n",
    "env = Environment(\n",
    "    conda_file=r\".\\model\\environment\\conda.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:latest\",\n",
    ")\n",
    "\n",
    "blue_deployment = KubernetesOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=loacl_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=r\".\\model\\onlinescoring\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_count=1,\n",
    "    resources=ResourceRequirementsSettings(\n",
    "        requests=ResourceSettings(\n",
    "            cpu=\"0.5\",\n",
    "            memory=\"0.5\",\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating local deployment (loacl04021040089783 / blue) .\n",
      "Building Docker image from Dockerfile\n",
      "Step 1/6 : FROM mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:latest\n",
      " ---> a0c1ac3e0de3\n",
      "Step 2/6 : RUN mkdir -p /var/azureml-app/\n",
      " ---> Using cache\n",
      " ---> 6933457dfc1d\n",
      "Step 3/6 : WORKDIR /var/azureml-app/\n",
      " ---> Using cache\n",
      " ---> ca2874ed4bad\n",
      "Step 4/6 : COPY conda.yml /var/azureml-app/\n",
      " ---> Using cache\n",
      " ---> 93effca0054d\n",
      "Step 5/6 : RUN conda env create -n inf-conda-env --file conda.yml\n",
      " ---> Using cache\n",
      " ---> 6be8b3970398\n",
      "Step 6/6 : CMD [\"conda\", \"run\", \"--no-capture-output\", \"-n\", \"inf-conda-env\", \"runsvdir\", \"/var/runit\"]\n",
      " ---> Using cache\n",
      " ---> 41e036971a20\n",
      "Successfully built 41e036971a20\n",
      "Successfully tagged loacl04021040089783:blue\n",
      "\n",
      "Starting up endpoint.....Done (0m 30s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KubernetesOnlineDeployment({'provisioning_state': 'Succeeded', 'endpoint_name': 'loacl04021040089783', 'type': 'Kubernetes', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': WindowsPath('c:/Users/leopu/OneDrive/Programming/Python/azure/kubernetes-deployment'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000017870B35DC0>, 'model': Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': '7713d7a5680d37a33a7ac52530aec294', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': WindowsPath('c:/Users/leopu/OneDrive/Programming/Python/azure/kubernetes-deployment'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000017870B536A0>, 'version': '1', 'latest_version': None, 'path': 'C:\\\\Users\\\\leopu\\\\OneDrive\\\\Programming\\\\Python\\\\azure\\\\kubernetes-deployment\\\\model\\\\model\\\\sklearn_regression_model.pkl', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'}), 'code_configuration': {'code': '.\\\\model\\\\onlinescoring'}, 'environment': Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'CliV2AnonymousEnvironment', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': WindowsPath('c:/Users/leopu/OneDrive/Programming/Python/azure/kubernetes-deployment'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000017870B5D520>, 'version': 'bdcf12a0fd05528360cc85db65d26305', 'latest_version': None, 'conda_file': {'name': 'model-env', 'channels': ['conda-forge'], 'dependencies': ['python=3.7', 'numpy=1.21.2', 'pip=21.2.4', 'scikit-learn=0.24.2', 'scipy=1.7.1', {'pip': ['azureml-defaults==1.47.0', 'inference-schema[numpy-support]==1.5', 'joblib==1.0.1']}]}, 'image': 'mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:latest', 'build': None, 'inference_config': None, 'os_type': None, 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': 'channels:\\n- conda-forge\\ndependencies:\\n- python=3.7\\n- numpy=1.21.2\\n- pip=21.2.4\\n- scikit-learn=0.24.2\\n- scipy=1.7.1\\n- pip:\\n  - azureml-defaults==1.47.0\\n  - inference-schema[numpy-support]==1.5\\n  - joblib==1.0.1\\nname: model-env\\n'}), 'environment_variables': {}, 'app_insights_enabled': False, 'scale_settings': None, 'request_settings': None, 'liveness_probe': None, 'readiness_probe': None, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'local', 'resources': <azure.ai.ml.entities._deployment.resource_requirements_settings.ResourceRequirementsSettings object at 0x0000017870B53550>})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(blue_deployment, local=True, vscode_debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-02T11:38:41,166859396+00:00 - rsyslog/run \n",
      "2023-04-02T11:38:41,167476389+00:00 - nginx/run \n",
      "2023-04-02T11:38:41,168097479+00:00 - gunicorn/run \n",
      "2023-04-02T11:38:41,168747975+00:00 | gunicorn/run | \n",
      "nginx: [warn] the \"user\" directive makes sense only if the master process runs with super-user privileges, ignored in /etc/nginx/nginx.conf:1\n",
      "2023-04-02T11:38:41,169563187+00:00 | gunicorn/run | ###############################################\n",
      "2023-04-02T11:38:41,170672628+00:00 | gunicorn/run | AzureML Container Runtime Information\n",
      "2023-04-02T11:38:41,171335608+00:00 | gunicorn/run | ###############################################\n",
      "2023-04-02T11:38:41,171984155+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:41,172709239+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:41,173892941+00:00 | gunicorn/run | AzureML image information: minimal-ubuntu18.04-py37-cpu-inference:20230227.v13\n",
      "2023-04-02T11:38:41,174454576+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:41,175008112+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:41,175614074+00:00 | gunicorn/run | PATH environment variable: /opt/miniconda/envs/inf-conda-env/bin:/opt/miniconda/condabin:/opt/miniconda/envs/amlenv/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "2023-04-02T11:38:41,176181793+00:00 | gunicorn/run | PYTHONPATH environment variable: \n",
      "2023-04-02T11:38:41,176754874+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:41,479392858+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n",
      "\n",
      "# conda environments:\n",
      "#\n",
      "base                     /opt/miniconda\n",
      "amlenv                   /opt/miniconda/envs/amlenv\n",
      "inf-conda-env         *  /opt/miniconda/envs/inf-conda-env\n",
      "\n",
      "2023-04-02T11:38:42,071584037+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:42,072306855+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n",
      "\n",
      "adal==1.2.7\n",
      "argcomplete==2.1.2\n",
      "attrs==22.2.0\n",
      "azure-common==1.1.28\n",
      "azure-core==1.26.3\n",
      "azure-graphrbac==0.61.1\n",
      "azure-identity==1.7.0\n",
      "azure-mgmt-authorization==2.0.0\n",
      "azure-mgmt-containerregistry==10.1.0\n",
      "azure-mgmt-core==1.3.2\n",
      "azure-mgmt-keyvault==10.1.0\n",
      "azure-mgmt-resource==21.2.1\n",
      "azure-mgmt-storage==20.1.0\n",
      "azureml-core==1.47.0\n",
      "azureml-dataprep==4.5.7\n",
      "azureml-dataprep-native==38.0.0\n",
      "azureml-dataprep-rslex==2.11.4\n",
      "azureml-dataset-runtime==1.47.0\n",
      "azureml-defaults==1.47.0\n",
      "azureml-inference-server-http==0.7.7\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt==4.0.1\n",
      "cachetools==5.3.0\n",
      "certifi==2022.12.7\n",
      "cffi==1.15.1\n",
      "charset-normalizer==3.1.0\n",
      "click==8.1.3\n",
      "cloudpickle==2.2.1\n",
      "configparser==3.7.4\n",
      "contextlib2==21.6.0\n",
      "cryptography==38.0.4\n",
      "distro==1.8.0\n",
      "docker==6.0.1\n",
      "dotnetcore2==3.1.23\n",
      "Flask==2.2.3\n",
      "Flask-Cors==3.0.10\n",
      "fusepy==3.0.1\n",
      "google-api-core==2.11.0\n",
      "google-auth==2.17.1\n",
      "googleapis-common-protos==1.59.0\n",
      "gunicorn==20.1.0\n",
      "humanfriendly==10.0\n",
      "idna==3.4\n",
      "importlib-metadata==5.2.0\n",
      "importlib-resources==5.12.0\n",
      "inference-schema==1.5\n",
      "isodate==0.6.1\n",
      "itsdangerous==2.1.2\n",
      "jeepney==0.8.0\n",
      "Jinja2==3.1.2\n",
      "jmespath==1.0.1\n",
      "joblib==1.0.1\n",
      "json-logging-py==0.2\n",
      "jsonpickle==2.2.0\n",
      "jsonschema==4.17.3\n",
      "knack==0.10.1\n",
      "MarkupSafe==2.1.2\n",
      "msal==1.21.0\n",
      "msal-extensions==0.3.1\n",
      "msrest==0.7.1\n",
      "msrestazure==0.6.4\n",
      "ndg-httpsclient==0.5.1\n",
      "numpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1629092064233/work\n",
      "oauthlib==3.2.2\n",
      "opencensus==0.11.2\n",
      "opencensus-context==0.1.3\n",
      "opencensus-ext-azure==1.1.9\n",
      "packaging==21.3\n",
      "paramiko==2.12.0\n",
      "pathspec==0.11.1\n",
      "pkginfo==1.9.6\n",
      "pkgutil_resolve_name==1.3.10\n",
      "portalocker==2.7.0\n",
      "protobuf==4.22.1\n",
      "psutil==5.9.4\n",
      "pyarrow==9.0.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycparser==2.21\n",
      "Pygments==2.14.0\n",
      "PyJWT==2.6.0\n",
      "PyNaCl==1.5.0\n",
      "pyOpenSSL==22.1.0\n",
      "pyparsing==3.0.9\n",
      "pyrsistent==0.19.3\n",
      "PySocks==1.7.1\n",
      "python-dateutil==2.8.2\n",
      "pytz==2023.3\n",
      "PyYAML==6.0\n",
      "requests==2.28.2\n",
      "requests-oauthlib==1.3.1\n",
      "rsa==4.9\n",
      "scikit-learn @ file:///home/conda/feedstock_root/build_artifacts/scikit-learn_1630910536896/work\n",
      "scipy @ file:///home/conda/feedstock_root/build_artifacts/scipy_1628206376058/work\n",
      "SecretStorage==3.3.3\n",
      "six==1.16.0\n",
      "tabulate==0.9.0\n",
      "threadpoolctl @ file:///home/conda/feedstock_root/build_artifacts/threadpoolctl_1643647933166/work\n",
      "typing_extensions==4.5.0\n",
      "urllib3==1.26.15\n",
      "websocket-client==1.5.1\n",
      "Werkzeug==2.2.3\n",
      "wrapt==1.12.1\n",
      "zipp==3.15.0\n",
      "\n",
      "2023-04-02T11:38:42,349859428+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:42,350544331+00:00 | gunicorn/run | Entry script directory: /var/azureml-app/onlinescoring//.\n",
      "2023-04-02T11:38:42,351163676+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:42,352034941+00:00 | gunicorn/run | ###############################################\n",
      "2023-04-02T11:38:42,352867091+00:00 | gunicorn/run | Dynamic Python Package Installation\n",
      "2023-04-02T11:38:42,353719622+00:00 | gunicorn/run | ###############################################\n",
      "2023-04-02T11:38:42,354400988+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:42,355049826+00:00 | gunicorn/run | Dynamic Python package installation is disabled.\n",
      "2023-04-02T11:38:42,355714230+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:42,356374871+00:00 | gunicorn/run | ###############################################\n",
      "2023-04-02T11:38:42,356995827+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n",
      "2023-04-02T11:38:42,357564348+00:00 | gunicorn/run | ###############################################\n",
      "2023-04-02T11:38:42,358179157+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:42,900710047+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:42,901451702+00:00 | gunicorn/run | ###############################################\n",
      "2023-04-02T11:38:42,902236927+00:00 | gunicorn/run | AzureML Inference Server\n",
      "2023-04-02T11:38:42,903251737+00:00 | gunicorn/run | ###############################################\n",
      "2023-04-02T11:38:42,904189596+00:00 | gunicorn/run | \n",
      "2023-04-02T11:38:42,909485210+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n",
      "\n",
      "Azure ML Inferencing HTTP server v0.7.7\n",
      "\n",
      "\n",
      "Server Settings\n",
      "---------------\n",
      "Entry Script Name: /var/azureml-app/onlinescoring/score.py\n",
      "Model Directory: /var/azureml-app/azureml-models//7713d7a5680d37a33a7ac52530aec294/1\n",
      "Worker Count: 1\n",
      "Worker Timeout (seconds): 300\n",
      "Server Port: 31311\n",
      "Application Insights Enabled: false\n",
      "Application Insights Key: None\n",
      "Inferencing HTTP server version: azmlinfsrv/0.7.7\n",
      "CORS for the specified origins: None\n",
      "\n",
      "\n",
      "Server Routes\n",
      "---------------\n",
      "Liveness Probe: GET   127.0.0.1:31311/\n",
      "Score:          POST  127.0.0.1:31311/score\n",
      "\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://0.0.0.0:31311 (22)\n",
      "Using worker: sync\n",
      "Booting worker with pid: 97\n",
      "Initializing logger\n",
      "2023-04-02 11:38:43,290 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2023-04-02 11:38:43,291 | root | INFO | Starting up app insight hooks\n",
      "2023-04-02 11:38:43,393 | root | INFO | Found user script at /var/azureml-app/onlinescoring/score.py\n",
      "2023-04-02 11:38:43,393 | root | INFO | run() is not decorated. Server will invoke it with the input in JSON string.\n",
      "2023-04-02 11:38:43,393 | root | INFO | Invoking user's init function\n",
      "Init complete\n",
      "2023-04-02 11:38:43,588 | root | INFO | Users's init has completed successfully\n",
      "2023-04-02 11:38:43,589 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\n",
      "2023-04-02 11:38:43,590 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2023-04-02 11:38:43,590 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check log of deployment (also useful if you want to debug your deployment)\n",
    "debug_logs = ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=loacl_endpoint_name, lines=1000, local=True\n",
    ")\n",
    "print(debug_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KubernetesOnlineDeployment({'provisioning_state': 'Succeeded', 'endpoint_name': 'loacl04021040089783', 'type': 'Kubernetes', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': WindowsPath('c:/Users/leopu/OneDrive/Programming/Python/azure/kubernetes-deployment'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000017870B5D4C0>, 'model': Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': '7713d7a5680d37a33a7ac52530aec294', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': WindowsPath('c:/Users/leopu/OneDrive/Programming/Python/azure/kubernetes-deployment'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000017870B35E80>, 'version': '1', 'latest_version': None, 'path': 'C:\\\\Users\\\\leopu\\\\OneDrive\\\\Programming\\\\Python\\\\azure\\\\kubernetes-deployment\\\\model\\\\model\\\\sklearn_regression_model.pkl', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'}), 'code_configuration': {'code': '.\\\\model\\\\onlinescoring'}, 'environment': Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'CliV2AnonymousEnvironment', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': WindowsPath('c:/Users/leopu/OneDrive/Programming/Python/azure/kubernetes-deployment'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000017870C151C0>, 'version': 'bdcf12a0fd05528360cc85db65d26305', 'latest_version': None, 'conda_file': {'name': 'model-env', 'channels': ['conda-forge'], 'dependencies': ['python=3.7', 'numpy=1.21.2', 'pip=21.2.4', 'scikit-learn=0.24.2', 'scipy=1.7.1', {'pip': ['azureml-defaults==1.47.0', 'inference-schema[numpy-support]==1.5', 'joblib==1.0.1']}]}, 'image': 'mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:latest', 'build': None, 'inference_config': None, 'os_type': None, 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': 'channels:\\n- conda-forge\\ndependencies:\\n- python=3.7\\n- numpy=1.21.2\\n- pip=21.2.4\\n- scikit-learn=0.24.2\\n- scipy=1.7.1\\n- pip:\\n  - azureml-defaults==1.47.0\\n  - inference-schema[numpy-support]==1.5\\n  - joblib==1.0.1\\nname: model-env\\n'}), 'environment_variables': {}, 'app_insights_enabled': False, 'scale_settings': None, 'request_settings': None, 'liveness_probe': None, 'readiness_probe': None, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'local', 'resources': <azure.ai.ml.entities._deployment.resource_requirements_settings.ResourceRequirementsSettings object at 0x0000017870C154C0>})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_deployments.get(name=\"blue\", endpoint_name=loacl_endpoint_name, local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[11055.977245525679, 4503.079536107787]'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke local endpoint \n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=loacl_endpoint_name,\n",
    "    request_file=r\".\\model\\sample-request.json\",\n",
    "    local=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the model to AKS\n",
    "import datetime \n",
    "\n",
    "online_endpoint_name = \"k8s-endpoint\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = KubernetesOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    compute=\"moby\",\n",
    "    description=\"this is a sample k8s endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"key\": \"test_deplyoment\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KubernetesOnlineEndpoint({'provisioning_state': 'Succeeded', 'scoring_uri': 'http://20.123.111.254/api/v1/endpoint/k8s-endpoint04071846339402/score', 'openapi_uri': 'http://20.123.111.254/api/v1/endpoint/k8s-endpoint04071846339402/swagger.json', 'name': 'k8s-endpoint04071846339402', 'description': 'this is a sample k8s endpoint', 'tags': {'key': 'test_deplyoment'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourcegroups/mlgroup/providers/microsoft.machinelearningservices/workspaces/mlworkspace/onlineendpoints/k8s-endpoint04071846339402', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/providers/Microsoft.MachineLearningServices/locations/northeurope/mfeOperationsStatus/oe:6888f348-7a7b-4570-a119-b500be349475:4847a014-7ebb-459d-a454-15caf4697f6a?api-version=2022-02-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourceGroups/MlGroup/providers/Microsoft.MachineLearningServices/workspaces/mlworkspace/onlineEndpoints/k8s-endpoint04071846339402', 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\leopu\\\\OneDrive\\\\Programming\\\\Python\\\\azure\\\\kubernetes-deployment', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x00000201A6DCED30>, 'auth_mode': 'key', 'location': 'northeurope', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x00000201A6DCEF70>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'K8S', 'compute': '/subscriptions/5a361d37-b562-4eee-981b-0936493063e9/resourceGroups/MlGroup/providers/Microsoft.MachineLearningServices/workspaces/mlworkspace/computes/moby'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the deployment\n",
    "model = Model(path=r\".\\model\\model\\sklearn_regression_model.pkl\")\n",
    "env = Environment(\n",
    "    conda_file=r\".\\model\\environment\\conda.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:latest\",\n",
    ")\n",
    "\n",
    "blue_deployment = KubernetesOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=r\".\\model\\onlinescoring\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_count=1,\n",
    "    resources=ResourceRequirementsSettings(\n",
    "        requests=ResourceSettings(\n",
    "            cpu=\"100m\",\n",
    "            memory=\"0.5Gi\",\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint k8s-endpoint04071846339402 exists\n",
      "\u001b[32mUploading onlinescoring (0.0 MBs): 100%|##########| 2473/2473 [00:00<00:00, 11706.61it/s]\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading sklearn_regression_model.pkl\u001b[32m (< 1 MB): 100%|##########| 756/756 [00:00<00:00, 15.5kB/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................."
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(DeploymentFailed) InferencingClient HttpRequest error, error detail: {\"errors\":{\"\":[\"Resource requests for CPU and memory must not be null. If GPU is specified, resource limits for CPU and memory must also not be null. For both requests and limits, if specified, cpu must be greater than 1m and memory must be greater than 1Mi.\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-517c3b80ee5b3cb905d866a94e45f22d-7776c6142e68b4f0-00\"}\nCode: DeploymentFailed\nMessage: InferencingClient HttpRequest error, error detail: {\"errors\":{\"\":[\"Resource requests for CPU and memory must not be null. If GPU is specified, resource limits for CPU and memory must also not be null. For both requests and limits, if specified, cpu must be greater than 1m and memory must be greater than 1Mi.\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-517c3b80ee5b3cb905d866a94e45f22d-7776c6142e68b4f0-00\"}\nException Details:\t(DeploymentFailed) InferencingClient HttpRequest error, error detail: {\"errors\":{\"\":[\"Resource requests for CPU and memory must not be null. If GPU is specified, resource limits for CPU and memory must also not be null. For both requests and limits, if specified, cpu must be greater than 1m and memory must be greater than 1Mi.\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-517c3b80ee5b3cb905d866a94e45f22d-7776c6142e68b4f0-00\"}\n\tThe build log is available in the workspace blob store \"mlstorageleo\" under the path \"/azureml/ImageLogs/477892dc-7748-49ed-aa0b-9612a1729a81/build.log\"\n\tCode: DeploymentFailed\n\tMessage: InferencingClient HttpRequest error, error detail: {\"errors\":{\"\":[\"Resource requests for CPU and memory must not be null. If GPU is specified, resource limits for CPU and memory must also not be null. For both requests and limits, if specified, cpu must be greater than 1m and memory must be greater than 1Mi.\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-517c3b80ee5b3cb905d866a94e45f22d-7776c6142e68b4f0-00\"}\n\tThe build log is available in the workspace blob store \"mlstorageleo\" under the path \"/azureml/ImageLogs/477892dc-7748-49ed-aa0b-9612a1729a81/build.log\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationFailed\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\azure\\core\\polling\\base_polling.py:500\u001b[0m, in \u001b[0;36mLROBasePolling.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 500\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll()\n\u001b[0;32m    502\u001b[0m \u001b[39mexcept\u001b[39;00m BadStatus \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\azure\\core\\polling\\base_polling.py:538\u001b[0m, in \u001b[0;36mLROBasePolling._poll\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[39mif\u001b[39;00m _failed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus()):\n\u001b[1;32m--> 538\u001b[0m     \u001b[39mraise\u001b[39;00m OperationFailed(\u001b[39m\"\u001b[39m\u001b[39mOperation failed or canceled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    540\u001b[0m final_get_url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operation\u001b[39m.\u001b[39mget_final_get_url(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_response)\n",
      "\u001b[1;31mOperationFailed\u001b[0m: Operation failed or canceled",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ml_client\u001b[39m.\u001b[39;49mbegin_create_or_update(blue_deployment)\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\azure\\core\\polling\\_poller.py:253\u001b[0m, in \u001b[0;36mLROPoller.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult\u001b[39m(\u001b[39mself\u001b[39m, timeout: Optional[\u001b[39mfloat\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PollingReturnType:\n\u001b[0;32m    246\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[39m    the result available after the specified timeout.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_polling_method\u001b[39m.\u001b[39mresource()\n",
      "File \u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\azure\\core\\polling\\_poller.py:272\u001b[0m, in \u001b[0;36mLROPoller.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_thread\u001b[39m.\u001b[39mjoin(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    269\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[39m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[0;32m    271\u001b[0m     \u001b[39m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[1;32m--> 272\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# Was None\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\azure\\core\\polling\\_poller.py:189\u001b[0m, in \u001b[0;36mLROPoller._start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Start the long running operation.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[39mOn completion, runs any callbacks.\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \n\u001b[0;32m    185\u001b[0m \u001b[39m:param callable update_cmd: The API request to check the status of\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m the operation.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_polling_method\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m    190\u001b[0m \u001b[39mexcept\u001b[39;00m AzureError \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m error\u001b[39m.\u001b[39mcontinuation_token:\n",
      "File \u001b[1;32mc:\\Users\\leopu\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\azure\\core\\polling\\base_polling.py:517\u001b[0m, in \u001b[0;36mLROBasePolling.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[39mraise\u001b[39;00m HttpResponseError(\n\u001b[0;32m    511\u001b[0m         response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_response\u001b[39m.\u001b[39mhttp_response,\n\u001b[0;32m    512\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(err),\n\u001b[0;32m    513\u001b[0m         error\u001b[39m=\u001b[39merr,\n\u001b[0;32m    514\u001b[0m     )\n\u001b[0;32m    516\u001b[0m \u001b[39mexcept\u001b[39;00m OperationFailed \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 517\u001b[0m     \u001b[39mraise\u001b[39;00m HttpResponseError(\n\u001b[0;32m    518\u001b[0m         response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_response\u001b[39m.\u001b[39mhttp_response, error\u001b[39m=\u001b[39merr\n\u001b[0;32m    519\u001b[0m     )\n",
      "\u001b[1;31mHttpResponseError\u001b[0m: (DeploymentFailed) InferencingClient HttpRequest error, error detail: {\"errors\":{\"\":[\"Resource requests for CPU and memory must not be null. If GPU is specified, resource limits for CPU and memory must also not be null. For both requests and limits, if specified, cpu must be greater than 1m and memory must be greater than 1Mi.\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-517c3b80ee5b3cb905d866a94e45f22d-7776c6142e68b4f0-00\"}\nCode: DeploymentFailed\nMessage: InferencingClient HttpRequest error, error detail: {\"errors\":{\"\":[\"Resource requests for CPU and memory must not be null. If GPU is specified, resource limits for CPU and memory must also not be null. For both requests and limits, if specified, cpu must be greater than 1m and memory must be greater than 1Mi.\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-517c3b80ee5b3cb905d866a94e45f22d-7776c6142e68b4f0-00\"}\nException Details:\t(DeploymentFailed) InferencingClient HttpRequest error, error detail: {\"errors\":{\"\":[\"Resource requests for CPU and memory must not be null. If GPU is specified, resource limits for CPU and memory must also not be null. For both requests and limits, if specified, cpu must be greater than 1m and memory must be greater than 1Mi.\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-517c3b80ee5b3cb905d866a94e45f22d-7776c6142e68b4f0-00\"}\n\tThe build log is available in the workspace blob store \"mlstorageleo\" under the path \"/azureml/ImageLogs/477892dc-7748-49ed-aa0b-9612a1729a81/build.log\"\n\tCode: DeploymentFailed\n\tMessage: InferencingClient HttpRequest error, error detail: {\"errors\":{\"\":[\"Resource requests for CPU and memory must not be null. If GPU is specified, resource limits for CPU and memory must also not be null. For both requests and limits, if specified, cpu must be greater than 1m and memory must be greater than 1Mi.\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-517c3b80ee5b3cb905d866a94e45f22d-7776c6142e68b4f0-00\"}\n\tThe build log is available in the workspace blob store \"mlstorageleo\" under the path \"/azureml/ImageLogs/477892dc-7748-49ed-aa0b-9612a1729a81/build.log\""
     ]
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(blue_deployment).result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdk-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
